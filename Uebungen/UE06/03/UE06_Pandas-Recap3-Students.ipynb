{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 12 - Pandas Recap 3\n",
    "\n",
    "Arbeiten Sie nachfolgenden Aufgabenstellungen durch und dokumentieren Sie, wenn notwendig, ihre Erkenntnisse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12.1\n",
    "\n",
    "Erstellen Sie a) das DataFrame `person_df` mit folgendem Inhalt:\n",
    "\n",
    "<table>\n",
    "    <tr><th></th><th>Gewicht</th><th>Größe</th></tr>\n",
    "     <tr><td>Henry</td><td>75</td><td>179</td></tr>\n",
    "    <tr><td>Sarah</td><td>68</td><td>165</td></tr>\n",
    "    <tr><td>Elke</td><td>68</td><td>172</td></tr>\n",
    "    <tr><td>Susi</td><td>55</td><td>164</td></tr>\n",
    "    <tr><td>Vera</td><td>58</td><td>160</td></tr>\n",
    "    <tr><td>Toni</td><td>99</td><td>189</td></tr>\n",
    "    <tr><td>Maria</td><td>68</td><td>176</td></tr>\n",
    "    <tr><td>Chris</td><td>60</td><td>175</td></tr>    \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Größe  Gewicht\n",
      "0  Henry    179       75\n",
      "1  Sarah    165       68\n",
      "2   Elke    172       68\n",
      "3   Susi    164       55\n",
      "4   Vera    160       58\n",
      "5   Toni    189       99\n",
      "6  Maria    176       68\n",
      "7  Chris    175       60\n"
     ]
    }
   ],
   "source": [
    "data = { \"Name\" : [\"Henry\", \"Sarah\", \"Elke\",\n",
    "                      \"Susi\", \"Vera\", \"Toni\",\n",
    "                      \"Maria\", \"Chris\"],\n",
    "            \"Größe\" : [179, 165, 172, 164, 160,\n",
    "                       189, 176, 175],\n",
    "            \"Gewicht\" : [75, 68, 68, 55, 58, 99, 68, 60]\n",
    "           }\n",
    "\n",
    "person_df = pd.DataFrame(data)\n",
    "\n",
    "print(person_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der sog. *Body Mass Index* [1] berechnet sich durch:\n",
    "\n",
    "$$\n",
    "BMI = \\frac{\\text{Gewicht in Kilogramm}}{\\left(\\text{Größe in Metern}\\right)^2}\n",
    "$$\n",
    "\n",
    "\n",
    "Berechnen Sie b) den BMI für alle Personen des DataFrames `person_df` und geben Sie ausschließlich jene aus, deren BMI > 20 und < 25 ist. \n",
    "\n",
    "**Hinweis**: Erstellen Sie KEINE neue Spalte im DataFrame. Es ist ausschließlich folgendes Ergebnis in der Zelle auszugeben:\n",
    "\n",
    "```Python\n",
    "Henry    23.407509 \n",
    "Sarah    24.977043 \n",
    "Elke     22.985398  \n",
    "Susi     20.449137  \n",
    "Vera     22.656250  \n",
    "Maria    21.952479\n",
    "dtype: float64\n",
    "``` \n",
    "[1] https://de.wikipedia.org/wiki/Body-Mass-Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "Henry    23.407509\n",
      "Sarah    24.977043\n",
      "Elke     22.985398\n",
      "Susi     20.449137\n",
      "Vera     22.656250\n",
      "Maria    21.952479\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "bmi = person_df['Gewicht'] / (person_df['Größe'] ** 2)\n",
    "filtered_bmi = bmi[(bmi > 20) & (bmi < 25)]\n",
    "\n",
    "# Namen mit BMI anzeigen\n",
    "result = pd.Series(filtered_bmi.values, index=person_df['Name'][filtered_bmi.index])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Berechnung erfolgreich war, fügen Sie c) die ermittelten Werte (je Person) dem DataFrame `person_df` hinzu. Als Spaltenname ist *BMI* zu wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Größe  Gewicht        BMI\n",
      "0  Henry   1.79       75  23.407509\n",
      "1  Sarah   1.65       68  24.977043\n",
      "2   Elke   1.72       68  22.985398\n",
      "3   Susi   1.64       55  20.449137\n",
      "4   Vera   1.60       58  22.656250\n",
      "5   Toni   1.89       99  27.714790\n",
      "6  Maria   1.76       68  21.952479\n",
      "7  Chris   1.75       60  19.591837\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "person_df['BMI'] = person_df['Gewicht'] / (person_df['Größe'] ** 2)\n",
    "\n",
    "print(person_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geben Sie d) das erzeugte DataFrame absteigend sortiert nach dem BMI aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Größe  Gewicht        BMI\n",
      "5   Toni   1.89       99  27.714790\n",
      "1  Sarah   1.65       68  24.977043\n",
      "0  Henry   1.79       75  23.407509\n",
      "2   Elke   1.72       68  22.985398\n",
      "4   Vera   1.60       58  22.656250\n",
      "6  Maria   1.76       68  21.952479\n",
      "3   Susi   1.64       55  20.449137\n",
      "7  Chris   1.75       60  19.591837\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "# DataFrame nach BMI absteigend sortieren\n",
    "sorted_df = person_df.sort_values(by='BMI', ascending=False)\n",
    "\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12.2\n",
    "\n",
    "Laden Sie das bereitgestellte Dataset *parks.csv* und verschaffen Sie sich einen Überblick über dessen Aufbau bzw. Inhalt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df = pd.read_csv('parks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Geben Sie den Park aus, der an der 9ten Stelle liegt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Park Code                          CARE\n",
      "Park Name    Capitol Reef National Park\n",
      "State                                UT\n",
      "Acres                            241904\n",
      "Latitude                           38.2\n",
      "Longitude                       -111.17\n",
      "Name: 8, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "# Den neunten Park anhand des Park-Codes ausgeben\n",
    "park_ninth = parks_df.iloc[8]  # Die neunte Zeile hat den Index 8 (Null-basiert)\n",
    "\n",
    "# Den Park ausgeben\n",
    "print(park_ninth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Geben Sie Parks aus an der  3, 12 und 24 Stelle aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Park Code                                    Park Name State   Acres  \\\n",
      "2       BADL                       Badlands National Park    SD  242756   \n",
      "11      CONG                       Congaree National Park    SC   26546   \n",
      "23      GRSA  Great Sand Dunes National Park and Preserve    CO   42984   \n",
      "\n",
      "    Latitude  Longitude  \n",
      "2      43.75    -102.50  \n",
      "11     33.78     -80.78  \n",
      "23     37.73    -105.51  \n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "parks_selected = parks_df.iloc[[2, 11, 23]]\n",
    "\n",
    "# Ausgegebenen Parks anzeigen\n",
    "print(parks_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Wie ist das DataFrame `park_df` zu ändern, dass die Abfrage `park_df.loc['BIBE']` durchläuft und somit folgendes Ergebnis liefert:\n",
    "\n",
    "```Python\n",
    "Park Name    Big Bend National Park\n",
    "State                            TX\n",
    "Acres                        801163\n",
    "Latitude                      29.25\n",
    "Longitude                   -103.25\n",
    "Name: BIBE, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Park Code'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14568\\367068173.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Setzen des Park-Codes als Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mparks_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Park Code'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Abfrage des Parks mit dem Code 'BIBE'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpark_bibe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparks_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BIBE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNone of \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m are in the columns\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Park Code'] are in the columns\""
     ]
    }
   ],
   "source": [
    "#c)\n",
    "# Setzen des Park-Codes als Index\n",
    "parks_df.set_index('Park Code', inplace=True)\n",
    "\n",
    "# Abfrage des Parks mit dem Code 'BIBE'\n",
    "park_bibe = parks_df.loc['BIBE']\n",
    "\n",
    "# Ausgabe des Ergebnisses\n",
    "print(park_bibe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Geben Sie die ersten drei sowie den 4., 5. und 6 Park aus (zwei separate Anfragen mit `iloc`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erste drei Parks:\n",
      "  Park Code               Park Name State   Acres  Latitude  Longitude\n",
      "0      ACAD    Acadia National Park    ME   47390     44.35     -68.21\n",
      "1      ARCH    Arches National Park    UT   76519     38.68    -109.57\n",
      "2      BADL  Badlands National Park    SD  242756     43.75    -102.50\n",
      "\n",
      "Parks an der 4., 5. und 6. Stelle:\n",
      "  Park Code                                   Park Name State   Acres  \\\n",
      "3      BIBE                      Big Bend National Park    TX  801163   \n",
      "4      BISC                      Biscayne National Park    FL  172924   \n",
      "5      BLCA  Black Canyon of the Gunnison National Park    CO   32950   \n",
      "\n",
      "   Latitude  Longitude  \n",
      "3     29.25    -103.25  \n",
      "4     25.65     -80.08  \n",
      "5     38.57    -107.72  \n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "# Erste drei Parks (Index 0, 1, 2)\n",
    "first_three_parks = parks_df.iloc[:3]\n",
    "\n",
    "# Ausgabe der ersten drei Parks\n",
    "print(\"Erste drei Parks:\")\n",
    "print(first_three_parks)\n",
    "\n",
    "# Parks an den Stellen 4, 5, 6 (Index 3, 4, 5)\n",
    "fourth_to_sixth_parks = parks_df.iloc[3:6]\n",
    "\n",
    "# Ausgabe des 4., 5. und 6. Parks\n",
    "print(\"\\nParks an der 4., 5. und 6. Stelle:\")\n",
    "print(fourth_to_sixth_parks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Gesucht ist folgende Ausgabe der Spalte *Park Code*:\n",
    "\n",
    "```Python\n",
    "0    ACAD\n",
    "1    ARCH\n",
    "2    BADL\n",
    "Name: Park Code, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ACAD\n",
      "1    ARCH\n",
      "2    BADL\n",
      "Name: Park Code, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "# Park Code Spalte extrahieren und die ersten drei Werte ausgeben\n",
    "park_codes = parks_df['Park Code'].head(3)\n",
    "\n",
    "# Ausgabe der ersten drei Park Codes\n",
    "print(park_codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spaltennamen mit Leerzeichen (und Großbuchstaben) sind eine potenzielle Fehlerquelle, die es zu eliminieren gilt. Ändern Sie f) die Spaltennamen durch den Einsatz von `replace(...)` und `lower(...)` in einer *List Comprehension*. **Wichtig**: Die Liste mit den neuen Spaltennamen ist in der *List Comprehension* zu erstellen. Warum wir eine Liste benötigen, ist durch das Property *columns* von *DataFrame* definiert. `new_column_names` gestaltet sich nach Abarbeitung der *List Comprehension* wie folgt:\n",
    "\n",
    "```Python\n",
    "['parkcode', 'parkname', 'state', 'acres', 'latitude', 'longitude']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['parkname', 'state', 'acres', 'latitude', 'longitude'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#f) \n",
    "# Neue Spaltennamen erstellen, Leerzeichen entfernen und alles in Kleinbuchstaben umwandeln\n",
    "new_column_names = [col.replace(' ', '').lower() for col in parks_df.columns]\n",
    "\n",
    "# Spaltennamen des DataFrames ändern\n",
    "parks_df.columns = new_column_names\n",
    "\n",
    "# Ausgabe der neuen Spaltennamen\n",
    "print(parks_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selektieren Sie g) den Parknamen und den Bundestaat der ersten 3 Zeilen im *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on Index with these indexers [2] of type int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#g)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Selektieren der Spalten 'parkname' und 'state' für die ersten 3 Zeilen\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m parks_df\u001b[38;5;241m.\u001b[39mloc[:\u001b[38;5;241m2\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparkname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Ausgabe des Ergebnisses\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(selected_columns)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(retval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1411\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1443\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1442\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1443\u001b[0m indexer \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mslice_indexer(slice_obj\u001b[38;5;241m.\u001b[39mstart, slice_obj\u001b[38;5;241m.\u001b[39mstop, slice_obj\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6662\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_indexer\u001b[39m(\n\u001b[0;32m   6619\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   6620\u001b[0m     start: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6621\u001b[0m     end: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6622\u001b[0m     step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mslice\u001b[39m:\n\u001b[0;32m   6624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6625\u001b[0m \u001b[38;5;124;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6626\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6660\u001b[0m \u001b[38;5;124;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6662\u001b[0m     start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_locs(start, end, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[0;32m   6664\u001b[0m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6885\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6883\u001b[0m end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 6885\u001b[0m     end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slice_bound(end, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6887\u001b[0m     end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6794\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6790\u001b[0m original_label \u001b[38;5;241m=\u001b[39m label\n\u001b[0;32m   6792\u001b[0m \u001b[38;5;66;03m# For datetime indices label may be a string that has to be converted\u001b[39;00m\n\u001b[0;32m   6793\u001b[0m \u001b[38;5;66;03m# to datetime boundary according to its resolution.\u001b[39;00m\n\u001b[1;32m-> 6794\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_slice_bound(label, side)\n\u001b[0;32m   6796\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6727\u001b[0m, in \u001b[0;36mIndex._maybe_cast_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6725\u001b[0m \u001b[38;5;66;03m# reject them, if index does not contain label\u001b[39;00m\n\u001b[0;32m   6726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (is_float(label) \u001b[38;5;129;01mor\u001b[39;00m is_integer(label)) \u001b[38;5;129;01mand\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m-> 6727\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_invalid_indexer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice\u001b[39m\u001b[38;5;124m\"\u001b[39m, label)\n\u001b[0;32m   6729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m label\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4301\u001b[0m, in \u001b[0;36mIndex._raise_invalid_indexer\u001b[1;34m(self, form, key, reraise)\u001b[0m\n\u001b[0;32m   4299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reraise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   4300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreraise\u001b[39;00m\n\u001b[1;32m-> 4301\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot do slice indexing on Index with these indexers [2] of type int"
     ]
    }
   ],
   "source": [
    "#g)\n",
    "# Selektieren der Spalten 'parkname' und 'state' für die ersten 3 Zeilen\n",
    "selected_columns = parks_df.loc[:2, ['parkname', 'state']]\n",
    "\n",
    "# Ausgabe des Ergebnisses\n",
    "print(selected_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Worin unterscheiden sich diese beiden Abfragen und was wäre eine logische Erklärung dafür?\n",
    "- `park_df.iloc[2]`\n",
    "- `park_df.iloc[[2]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parkname     Badlands National Park\n",
      "state                            SD\n",
      "acres                        242756\n",
      "latitude                      43.75\n",
      "longitude                    -102.5\n",
      "Name: BADL, dtype: object\n",
      "                         parkname state   acres  latitude  longitude\n",
      "Park Code                                                           \n",
      "BADL       Badlands National Park    SD  242756     43.75     -102.5\n"
     ]
    }
   ],
   "source": [
    "# h)\n",
    "# Eine einzelne Zeile als Series zurückgeben (Index 2)\n",
    "row_series = parks_df.iloc[2]  \n",
    "print(row_series)\n",
    "\n",
    "# Eine einzelne Zeile als DataFrame zurückgeben (Index 2)\n",
    "row_dataframe = parks_df.iloc[[2]]  \n",
    "print(row_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Welche Parks befinden sich im Bundesstaat Utah (UT)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Park Code                   Park Name State   Acres  Latitude  Longitude\n",
      "1       ARCH        Arches National Park    UT   76519     38.68    -109.57\n",
      "6       BRCA  Bryce Canyon National Park    UT   35835     37.57    -112.18\n",
      "7       CANY   Canyonlands National Park    UT  337598     38.20    -109.93\n",
      "8       CARE  Capitol Reef National Park    UT  241904     38.20    -111.17\n",
      "55      ZION          Zion National Park    UT  146598     37.30    -113.05\n"
     ]
    }
   ],
   "source": [
    "#i)\n",
    "# Parks im Bundesstaat Utah (UT) selektieren\n",
    "utah_parks = parks_df[parks_df['State'] == 'UT']\n",
    "\n",
    "# Ausgabe der Parks in Utah\n",
    "print(utah_parks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Welche Parks erfüllen folgende Bedingung? \n",
    "- latitude > 60 oder acres > 1.000.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Park Code                                       Park Name       State  \\\n",
      "14      DENA               Denali National Park and Preserve          AK   \n",
      "15      DEVA                      Death Valley National Park      CA, NV   \n",
      "17      EVER                        Everglades National Park          FL   \n",
      "18      GAAR  Gates Of The Arctic National Park and Preserve          AK   \n",
      "19      GLAC                           Glacier National Park          MT   \n",
      "20      GLBA          Glacier Bay National Park and Preserve          AK   \n",
      "22      GRCA                      Grand Canyon National Park          AZ   \n",
      "32      KATM               Katmai National Park and Preserve          AK   \n",
      "34      KOVA                      Kobuk Valley National Park          AK   \n",
      "35      LACL           Lake Clark National Park and Preserve          AK   \n",
      "52      WRST  Wrangell - St Elias National Park and Preserve          AK   \n",
      "53      YELL                       Yellowstone National Park  WY, MT, ID   \n",
      "\n",
      "      Acres  Latitude  Longitude  \n",
      "14  3372402     63.33    -150.50  \n",
      "15  4740912     36.24    -116.82  \n",
      "17  1508538     25.32     -80.93  \n",
      "18  7523898     67.78    -153.30  \n",
      "19  1013572     48.80    -114.00  \n",
      "20  3224840     58.50    -137.00  \n",
      "22  1217403     36.06    -112.14  \n",
      "32  3674530     58.50    -155.00  \n",
      "34  1750717     67.55    -159.28  \n",
      "35  2619733     60.97    -153.42  \n",
      "52  8323148     61.00    -142.00  \n",
      "53  2219791     44.60    -110.50  \n"
     ]
    }
   ],
   "source": [
    "#j)\n",
    "# Parks, bei denen die Bedingung 'latitude > 60 oder acres > 1.000.000' erfüllt ist\n",
    "selected_parks = parks_df[(parks_df['Latitude'] > 60) | (parks_df['Acres'] > 1000000)]\n",
    "\n",
    "# Ausgabe der ausgewählten Parks\n",
    "print(selected_parks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Finden Sie alle Parks, die sich in den Bundesstaaten *WA*, *OR* und *CA* befinden. Verwenden Sie hierzu `isin()` (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html?highlight=isin#pandas.DataFrame.isin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Park Code                                Park Name State   Acres  Latitude  \\\n",
      "10      CHIS            Channel Islands National Park    CA  249561     34.01   \n",
      "12      CRLA                Crater Lake National Park    OR  183224     42.94   \n",
      "31      JOTR                Joshua Tree National Park    CA  789745     33.79   \n",
      "36      LAVO            Lassen Volcanic National Park    CA  106372     40.49   \n",
      "39      MORA              Mount Rainier National Park    WA  235625     46.85   \n",
      "40      NOCA             North Cascades National Park    WA  504781     48.70   \n",
      "41      OLYM                    Olympic National Park    WA  922651     47.97   \n",
      "43      PINN                  Pinnacles National Park    CA   26606     36.48   \n",
      "44      REDW                    Redwood National Park    CA  112512     41.30   \n",
      "47      SEKI  Sequoia and Kings Canyon National Parks    CA  865952     36.43   \n",
      "54      YOSE                   Yosemite National Park    CA  761266     37.83   \n",
      "\n",
      "    Longitude  \n",
      "10    -119.42  \n",
      "12    -122.10  \n",
      "31    -115.90  \n",
      "36    -121.51  \n",
      "39    -121.75  \n",
      "40    -121.20  \n",
      "41    -123.50  \n",
      "43    -121.16  \n",
      "44    -124.00  \n",
      "47    -118.68  \n",
      "54    -119.50  \n"
     ]
    }
   ],
   "source": [
    "#k)\n",
    "# Parks in den Bundesstaaten WA, OR und CA selektieren\n",
    "selected_parks = parks_df[parks_df['State'].isin(['WA', 'OR', 'CA'])]\n",
    "\n",
    "# Ausgabe der ausgewählten Parks\n",
    "print(selected_parks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
