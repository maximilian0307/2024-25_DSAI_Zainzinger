{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Recap 2\n",
    "Arbeiten Sie nachfolgenden Aufgabenstellungen durch und dokumentieren Sie, wenn notwendig, ihre Erkenntnisse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Erstellen Sie basierend auf den 3 Listen `name`, `population` und `country` das *Dictionary* `cities`. Verwenden Sie die List-Bezeichner als *Keys*. Im nächsten Schritt gilt es mit dem *Dictionary* das *DataFrame* `citiy_df` zu erstellen. Gesuchte Ausgabe:\n",
    "\n",
    "```Python\n",
    "      name \tpoulation   country\n",
    "0 \tLondon \t8615246 \tEngland\n",
    "1 \tBerlin \t3562166 \tGermany\n",
    "2 \tMadrid \t3165235 \tSpain\n",
    "3 \tRome \t2874038 \tItaly\n",
    "4 \tParis \t2273305 \tFrance\n",
    "5 \tVienna \t1805681 \tAustria\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name  population  country\n",
      "0      London     8615246  England\n",
      "1      Berlin     3562166  Germany\n",
      "2      Madrid     3165235    Spain\n",
      "3        Rome     2874038    Italy\n",
      "4       Paris     2273305   France\n",
      "5      Vienna     1805681  Austria\n",
      "6   Bucharest     1803425  Romania\n",
      "7     Hamburg     1760433  Germany\n",
      "8    Budapest     1754000  Hungary\n",
      "9      Warsaw     1740119   Poland\n",
      "10  Barcelona     1602386    Spain\n",
      "11     Munich     1493900  Germany\n",
      "12      Milan     1350680    Italy\n"
     ]
    }
   ],
   "source": [
    "name = [\"London\", \"Berlin\", \"Madrid\", \"Rome\",\n",
    "        \"Paris\", \"Vienna\", \"Bucharest\", \"Hamburg\",\n",
    "        \"Budapest\", \"Warsaw\", \"Barcelona\",\n",
    "        \"Munich\", \"Milan\"]\n",
    "\n",
    "population = [8615246, 3562166, 3165235, 2874038,\n",
    "                2273305, 1805681, 1803425, 1760433,\n",
    "                1754000, 1740119, 1602386, 1493900,\n",
    "                1350680]\n",
    "\n",
    "country = [\"England\", \"Germany\", \"Spain\", \"Italy\",\n",
    "            \"France\", \"Austria\", \"Romania\",\n",
    "            \"Germany\", \"Hungary\", \"Poland\", \"Spain\",\n",
    "            \"Germany\", \"Italy\"]\n",
    "\n",
    "# Erstellen Dictionaries\n",
    "cities = {'name': name, 'population': population, 'country': country}\n",
    "\n",
    "city_df = pd.DataFrame(cities)\n",
    "\n",
    "print(city_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Die Reihenfolge der Spalten kann bei der Erstellung des *DataFrames* festgelegt werden. Dazu dient das Schlüsselwort `columns` beim Instanziieren eines *DataFrames*. Ändern Sie diese, sodass folgende Reihenfolge gegeben ist: *-name* - *country* - *population*. Verwenden Sie hierzu die Liste `new_order`. Erstellen Sie mit `city_df` ein neues *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name  country  population\n",
      "0      London  England     8615246\n",
      "1      Berlin  Germany     3562166\n",
      "2      Madrid    Spain     3165235\n",
      "3        Rome    Italy     2874038\n",
      "4       Paris   France     2273305\n",
      "5      Vienna  Austria     1805681\n",
      "6   Bucharest  Romania     1803425\n",
      "7     Hamburg  Germany     1760433\n",
      "8    Budapest  Hungary     1754000\n",
      "9      Warsaw   Poland     1740119\n",
      "10  Barcelona    Spain     1602386\n",
      "11     Munich  Germany     1493900\n",
      "12      Milan    Italy     1350680\n"
     ]
    }
   ],
   "source": [
    "new_order = [\"name\", \"country\", \"population\"]\n",
    "city_df= city_df[new_order]\n",
    "print(city_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Man kann den Index entweder beim Erstellen eines *DataFrames* explizit definieren oder mit `set_index()` im Nachhinein ändern. Definieren Sie die Spalte *country* als neuen Index bei `city_df`. Wichtig: `set_index()` liefert ein neues DF-Objekt, was wir aber nicht möchten. Die Änderung soll in `city_df` direkt erfolgen!\n",
    "\n",
    "Quelle: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html?highlight=set_index#pandas-dataframe-set-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  population\n",
      "country                       \n",
      "England     London     8615246\n",
      "Germany     Berlin     3562166\n",
      "Spain       Madrid     3165235\n",
      "Italy         Rome     2874038\n",
      "France       Paris     2273305\n",
      "Austria     Vienna     1805681\n",
      "Romania  Bucharest     1803425\n",
      "Germany    Hamburg     1760433\n",
      "Hungary   Budapest     1754000\n",
      "Poland      Warsaw     1740119\n",
      "Spain    Barcelona     1602386\n",
      "Germany     Munich     1493900\n",
      "Italy        Milan     1350680\n"
     ]
    }
   ],
   "source": [
    "# 'country' als neuen Index setzen und Änderung direkt speichern\n",
    "city_df.set_index('country', inplace=True)\n",
    "print(city_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Gesucht sind a) alle Städte Deutschlands und b) alle Städt Deutschlands und Frankreichs. Zur Erinnerung: Die Spalte *country* bildet den Index.\n",
    "\n",
    "> **Remember**: `loc`und `iloc` durchsuchen ein *DataFrame* anhand des Index; es sind ausschließlich Werte der Index-Spalte zulässigt. Ignoriert man das, erhält man einen *Key Error*. Also bevor man loslegt, sollte man kurz innehalten und überlegen, was kann ich wie suchen und - hoffentlich - finden!\n",
    "\n",
    "Den Index eines DataFrames kann man mit dem Property `index` ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name  population\n",
      "country                     \n",
      "Germany   Berlin     3562166\n",
      "Germany  Hamburg     1760433\n",
      "Germany   Munich     1493900\n"
     ]
    }
   ],
   "source": [
    "# alle Städte aus Deutschland\n",
    "german_cities = city_df.loc[\"Germany\"]\n",
    "print(german_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name  population\n",
      "country                     \n",
      "Germany   Berlin     3562166\n",
      "Germany  Hamburg     1760433\n",
      "Germany   Munich     1493900\n",
      "France     Paris     2273305\n"
     ]
    }
   ],
   "source": [
    "# alle städte aus Frankreich und Deutschland\n",
    "selected_countries = city_df.loc[[\"Germany\", \"France\"]]\n",
    "print(selected_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Gesucht sind alle jene Städte, deren *Population* > 2Mio. ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name  population\n",
      "country                    \n",
      "England  London     8615246\n",
      "Germany  Berlin     3562166\n",
      "Spain    Madrid     3165235\n",
      "Italy      Rome     2874038\n",
      "France    Paris     2273305\n"
     ]
    }
   ],
   "source": [
    "large_cities = city_df[city_df['population'] > 2000000]\n",
    "print(large_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "Aufgabenstellung 8.5 kann man auf mehrere Arten lösen. Legen Sie dar, warum die `loc`-Variante funktioniert - vor allem unter den in 11.5 diskutierten Gesichtspunkten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Methode loc ist besonders nützlich, wenn wir auf Zeilen und Spalten basierend auf Labels zugreifen. \n",
    "#Da der Index von city_df die Länder sind, können wir mit loc nach Ländern (Index) filtern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "Berechnen Sie die Gesamtsumme der Einwohner aller Städte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesamtsumme der Bevölkerung: 33800614\n"
     ]
    }
   ],
   "source": [
    "total_population = city_df['population'].sum()\n",
    "print(f\"Gesamtsumme der Bevölkerung: {total_population}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "Fügen Sie dem *DataFrame* `city_df` die Spalte *area* mit den Werten der Liste `area` (Fläche in qkm) hinzu. Gesuchtes Ergebnis:\n",
    "\n",
    "```Python\n",
    "            name \tpopulation \tarea\n",
    "country \t\t\t\n",
    "England \tLondon \t8615246 \t1572.00\n",
    "Germany \tBerlin \t3562166 \t891.85\n",
    "Spain \t  Madrid \t3165235 \t605.77\n",
    "Italy \t  Rome \t  2874038     1285.00\n",
    "France \t Paris \t 2273305     105.40\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  population     area\n",
      "country                                \n",
      "England     London     8615246  1572.00\n",
      "Germany     Berlin     3562166   891.85\n",
      "Spain       Madrid     3165235   605.77\n",
      "Italy         Rome     2874038  1285.00\n",
      "France       Paris     2273305   105.40\n",
      "Austria     Vienna     1805681   414.87\n",
      "Romania  Bucharest     1803425   228.00\n",
      "Germany    Hamburg     1760433   755.00\n",
      "Hungary   Budapest     1754000   525.00\n",
      "Poland      Warsaw     1740119   517.00\n",
      "Spain    Barcelona     1602386   101.90\n",
      "Germany     Munich     1493900   310.70\n",
      "Italy        Milan     1350680   181.76\n"
     ]
    }
   ],
   "source": [
    "# Fläche in Quadratkilometern\n",
    "area = [1572.00, 891.85, 605.77, 1285.00, 105.40, 414.87, \n",
    "        228.00, 755.00, 525.00, 517.00, 101.90, 310.70, 181.76]\n",
    "\n",
    "# Spalte 'area' hinzufügen\n",
    "city_df['area'] = area\n",
    "print(city_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9\n",
    "Sortieren Sie die Ausgabe nach *area*, und zwar in absteigener Reihenfolge. Verwenden Sie `sort_values()`. Quelle: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  population     area\n",
      "country                                \n",
      "England     London     8615246  1572.00\n",
      "Italy         Rome     2874038  1285.00\n",
      "Germany     Berlin     3562166   891.85\n",
      "Germany    Hamburg     1760433   755.00\n",
      "Spain       Madrid     3165235   605.77\n",
      "Hungary   Budapest     1754000   525.00\n",
      "Poland      Warsaw     1740119   517.00\n",
      "Austria     Vienna     1805681   414.87\n",
      "Germany     Munich     1493900   310.70\n",
      "Romania  Bucharest     1803425   228.00\n",
      "Italy        Milan     1350680   181.76\n",
      "France       Paris     2273305   105.40\n",
      "Spain    Barcelona     1602386   101.90\n"
     ]
    }
   ],
   "source": [
    "sorted_city_df = city_df.sort_values(by='area', ascending=False)\n",
    "\n",
    "# Ausgabe anzeigen\n",
    "print(sorted_city_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10\n",
    "Nehmen Sie spätestens jetzt den Abschnitt *Applying Functions* des Tutorials **Python Pandas Tutorial: A Complete Introduction for Beginners** (siehe Übung 09) durch. \n",
    "\n",
    "Ziel ist die Erstellung einer weiteren Spalte *megacities*, die für alle Städte, der *population* > 2Mio. ist, den Wert `True` enthält. Erstellen Sie hierzu die Funktion `def calc_megacities(population)`, in welcher die Abfrage zu implementieren ist. Das gesuchte Ergebnis (die unordentliche Darstellung ist dem JN geschuldet):\n",
    "\n",
    "```Python\n",
    "            name \tpopulation \tarea \tmegacities\n",
    "country \t\t\t\t\n",
    "England \tLondon \t8615246 \t1572.00 \tTrue\n",
    "Italy       Rome \t2874038 \t1285.00 \tTrue\n",
    "Germany \tBerlin \t3562166 \t891.85 \t    True\n",
    "Germany \tHamburg 1760433 \t755.00 \t    False\n",
    "Spain \t    Madrid \t3165235 \t605.77 \t    True\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  population     area  megacities\n",
      "country                                            \n",
      "England     London     8615246  1572.00        True\n",
      "Germany     Berlin     3562166   891.85        True\n",
      "Spain       Madrid     3165235   605.77        True\n",
      "Italy         Rome     2874038  1285.00        True\n",
      "France       Paris     2273305   105.40        True\n",
      "Austria     Vienna     1805681   414.87       False\n",
      "Romania  Bucharest     1803425   228.00       False\n",
      "Germany    Hamburg     1760433   755.00       False\n",
      "Hungary   Budapest     1754000   525.00       False\n",
      "Poland      Warsaw     1740119   517.00       False\n",
      "Spain    Barcelona     1602386   101.90       False\n",
      "Germany     Munich     1493900   310.70       False\n",
      "Italy        Milan     1350680   181.76       False\n"
     ]
    }
   ],
   "source": [
    "# Funktion, die überprüft, ob die Stadt eine Megacity ist\n",
    "def calc_megacities(population):\n",
    "    return population > 2000000\n",
    "\n",
    "# Neue Spalte 'megacities' hinzufügen\n",
    "city_df['megacities'] = city_df['population'].apply(calc_megacities)\n",
    "\n",
    "# Ausgabe anzeigen\n",
    "print(city_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11\n",
    "\n",
    "Diese Aufgabe basiert auf einem Dataset, dass je Messzeitpunkt *t* sechs Temperaturwerte (Sensor 1 bis Sensor 6) umfasst. Das Messintervall betrug 15 Minuten.\n",
    "\n",
    "Laden Sie a) das bereitgestellte Dataset *temperatures_with_NaN.csv* und geben Sie die Shape aus. \n",
    "\n",
    "Geben Sie b) die ersten 5 Zeilen aller Sensoren aus. Geben Sie c) ausschließlich die ersten 5 Zeilen der Sensoren 3 und 4 aus. \n",
    "\n",
    "Ermitteln Sie d) die Anzahl der NaN-Werte je Sensor sowie je Zeitpunkt *t*. **Hinweis**: Denken Sie an die Achsen-Thematik, diese ist bei `sum()` konfigurierbar (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html?highlight=sum#pandas.DataFrame.sum. Ermitteln Sie außerdem die Gesamtanzahl der *NaN*-Werte. Hierzu ein kleiner Tipp: \"doppelt hält besser\"! \n",
    "\n",
    "e) Der letzte Punkte dieser Aufgabe widmet sich der Ermittlung des Mittelwertes zum Zeitpunkt t (siehe neue Spalte *mean*). Das gesuchte Ergebnis ist:\n",
    "\n",
    "```Python\n",
    "            time \tsensor1 \tsensor2 \tsensor3 \tsensor4 \tsensor5 \tsensor6 \tmean\n",
    "    0 \t06:00:00 \t14.3 \t    13.7 \t  14.2 \t  14.3 \t   13.5 \t  13.6 \t 13.933333\n",
    "    1 \t06:15:00 \t14.5 \t    14.5 \t  14.0 \t  15.0 \t   14.5 \t  14.7 \t 14.533333\n",
    "    3 \t06:45:00 \t14.8 \t    14.5 \t  15.6 \t  15.2 \t   14.7 \t  14.6 \t 14.900000\n",
    "    4 \t07:00:00 \t15.0 \t    14.9 \t  NaN \t   15.6 \t   14.0 \t  15.3 \t 14.960000\n",
    "    6 \t07:30:00 \t15.4 \t    15.3 \t  NaN \t   15.6 \t   14.7 \t  15.1 \t 15.220000\n",
    "```\n",
    "\n",
    "**Vorgehensweise**\n",
    "\n",
    "Es wird ersichtlich, dass z.B. die Messung zum Zeitpunkt t2 fehlt. Hintergrund ist, dass all jene Messungen entfernt wurden, die mehr als **einen** NaN-Wert aufwiesen. Das lässt sich mit `dropna()` überaus einfach bewerkstelligen (siehe Argument `thresh`). Hierbei ist die Gesamtanzahl der Spalten - also inkl. *time* - zu berücksichtigen! Entfernt man all jene Zeilen, die mehr als einen NaN-Wert enthalten, reduziert sich die Anzahl der Zeilen im Dataset auf 35.\n",
    "\n",
    "Den zweiten und letzten Schritt, um diese Aufgabe zu bewerkstelligen, stellt die Ermittlung des Mittelwertes je Messzeitpunkt t dar. Das Ergebnis ist in die neue Spalte *mean* zu schreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 7)\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "# Datei einlesen\n",
    "temperature_file_path = \"temperatures_with_NaN.csv\"  # Pfad zur Datei anpassen\n",
    "temp_df = pd.read_csv(temperature_file_path)\n",
    "\n",
    "# Shape der Daten anzeigen\n",
    "print(temp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       time  sensor1  sensor2  sensor3  sensor4  sensor5  sensor6\n",
      "0  06:00:00     14.3     13.7     14.2     14.3     13.5     13.6\n",
      "1  06:15:00     14.5     14.5     14.0     15.0     14.5     14.7\n",
      "2  06:30:00     14.6      NaN     14.8      NaN     14.0     14.2\n",
      "3  06:45:00     14.8     14.5     15.6     15.2     14.7     14.6\n",
      "4  07:00:00     15.0     14.9      NaN     15.6     14.0     15.3\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "# Erste 5 Zeilen der Datei anzeigen\n",
    "print(temp_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensor3  sensor4\n",
      "0     14.2     14.3\n",
      "1     14.0     15.0\n",
      "2     14.8      NaN\n",
      "3     15.6     15.2\n",
      "4      NaN     15.6\n"
     ]
    }
   ],
   "source": [
    "#c) \n",
    "# Nur die Sensoren 3 und 4 anzeigen\n",
    "print(temp_df[['sensor3', 'sensor4']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN-Werte je Sensor:\n",
      "time        0\n",
      "sensor1    11\n",
      "sensor2     8\n",
      "sensor3    13\n",
      "sensor4    15\n",
      "sensor5     9\n",
      "sensor6    11\n",
      "dtype: int64\n",
      "NaN-Werte je Zeitpunkt:\n",
      "0     0\n",
      "1     0\n",
      "2     2\n",
      "3     0\n",
      "4     1\n",
      "5     2\n",
      "6     1\n",
      "7     1\n",
      "8     3\n",
      "9     2\n",
      "10    3\n",
      "11    2\n",
      "12    0\n",
      "13    1\n",
      "14    2\n",
      "15    1\n",
      "16    0\n",
      "17    1\n",
      "18    0\n",
      "19    2\n",
      "20    1\n",
      "21    1\n",
      "22    0\n",
      "23    0\n",
      "24    1\n",
      "25    3\n",
      "26    2\n",
      "27    1\n",
      "28    0\n",
      "29    1\n",
      "30    2\n",
      "31    3\n",
      "32    4\n",
      "33    3\n",
      "34    3\n",
      "35    2\n",
      "36    2\n",
      "37    1\n",
      "38    1\n",
      "39    1\n",
      "40    1\n",
      "41    1\n",
      "42    0\n",
      "43    0\n",
      "44    2\n",
      "45    1\n",
      "46    0\n",
      "47    2\n",
      "48    0\n",
      "49    1\n",
      "50    1\n",
      "51    1\n",
      "52    0\n",
      "53    1\n",
      "dtype: int64\n",
      "Gesamtanzahl der NaN-Werte: 67\n"
     ]
    }
   ],
   "source": [
    "#d) \n",
    "# Anzahl der NaN-Werte je Sensor\n",
    "nan_per_sensor = temp_df.isna().sum(axis=0)\n",
    "print(\"NaN-Werte je Sensor:\")\n",
    "print(nan_per_sensor)\n",
    "\n",
    "# Anzahl der NaN-Werte je Zeitpunkt\n",
    "nan_per_time = temp_df.isna().sum(axis=1)\n",
    "print(\"NaN-Werte je Zeitpunkt:\")\n",
    "print(nan_per_time)\n",
    "\n",
    "# Gesamtanzahl der NaN-Werte\n",
    "total_nan = temp_df.isna().sum().sum()\n",
    "print(f\"Gesamtanzahl der NaN-Werte: {total_nan}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time  sensor1  sensor2  sensor3  sensor4  sensor5  sensor6       mean\n",
      "0   06:00:00     14.3     13.7     14.2     14.3     13.5     13.6  13.933333\n",
      "1   06:15:00     14.5     14.5     14.0     15.0     14.5     14.7  14.533333\n",
      "3   06:45:00     14.8     14.5     15.6     15.2     14.7     14.6  14.900000\n",
      "4   07:00:00     15.0     14.9      NaN     15.6     14.0     15.3  14.960000\n",
      "6   07:30:00     15.4     15.3      NaN     15.6     14.7     15.1  15.220000\n",
      "7   07:45:00     15.5     14.8     15.4     15.5      NaN     14.9  15.220000\n",
      "12  09:00:00     16.8     17.3     17.7     17.8     15.9     16.1  16.933333\n",
      "13  09:15:00     17.1     17.5     17.5     17.3     16.6      NaN  17.200000\n",
      "15  09:45:00     18.4     19.0     19.0      NaN     18.4     18.3  18.620000\n",
      "16  10:00:00     19.0     19.7     18.8     18.9     17.5     18.9  18.800000\n",
      "17  10:15:00     19.7     19.4      NaN     19.2     19.7     19.6  19.520000\n",
      "18  10:30:00     20.4     19.4     20.0     21.0     20.2     19.8  20.133333\n",
      "20  11:00:00     21.8     21.3      NaN     23.2     21.1     20.5  21.580000\n",
      "21  11:15:00      NaN     22.7     23.7     22.8     22.9     22.1  22.840000\n",
      "22  11:30:00     23.4     22.7     23.0     24.5     22.3     22.9  23.133333\n",
      "23  11:45:00     24.2     23.1     25.3     23.7     24.5     24.8  24.266667\n",
      "24  12:00:00     24.0     23.1     23.1      NaN     22.5     22.7  23.080000\n",
      "27  12:45:00     23.4     22.6     23.7     24.4      NaN     23.8  23.580000\n",
      "28  13:00:00     23.2     24.1     24.0     23.3     23.5     23.1  23.533333\n",
      "29  13:15:00     23.1     22.8     23.2     22.5     23.2      NaN  22.960000\n",
      "37  15:15:00     21.6     21.3     21.7      NaN     21.9     21.1  21.520000\n",
      "38  15:30:00     21.4     21.3      NaN     21.9     21.0     21.7  21.460000\n",
      "39  15:45:00     21.3     21.6     21.6     22.6      NaN     21.0  21.620000\n",
      "40  16:00:00     21.1     21.6     20.7     20.6      NaN     21.4  21.080000\n",
      "41  16:15:00      NaN     20.6     20.8     20.5     20.3     21.6  20.760000\n",
      "42  16:30:00     20.8     20.7     20.7     20.4     20.2     19.6  20.400000\n",
      "43  16:45:00     20.6     21.4     20.3     21.4     19.1     21.2  20.666667\n",
      "45  17:15:00     20.3     20.7     19.6     21.3     19.8      NaN  20.340000\n",
      "46  17:30:00     20.1     20.5     19.7     19.7     18.7     19.7  19.733333\n",
      "48  18:00:00     19.8     20.0     19.1     19.7     20.1     20.2  19.816667\n",
      "49  18:15:00     19.6     19.9      NaN     19.9     20.0     18.6  19.600000\n",
      "50  18:30:00     19.5     19.1     19.2      NaN     18.3     18.3  18.880000\n",
      "51  18:45:00     19.3     18.7     20.3     19.0     18.8      NaN  19.220000\n",
      "52  19:00:00     19.2     18.7     20.1     19.9     18.3     19.3  19.250000\n",
      "53  19:15:00     19.0     19.7     18.9     19.2     18.5      NaN  19.060000\n"
     ]
    }
   ],
   "source": [
    "# Zeilen mit mehr als einem NaN-Wert entfernen\n",
    "temp_df = temp_df.dropna(thresh=temp_df.shape[1] - 1)\n",
    "\n",
    "# Mittelwert je Messzeitpunkt berechnen\n",
    "temp_df['mean'] = temp_df.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "# Ausgabe anzeigen\n",
    "print(temp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
